{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> current directory : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\n",
      ">> cache path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\n",
      ">> model path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\models\n",
      ">> dataset path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\dataset\n",
      ">> logs path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\logs\n",
      ">> device : cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "cwd = os.getcwd().split(os.path.sep)\n",
    "\n",
    "# point to the git repository\n",
    "while cwd[-1] != \"ExplanationPairSentencesTasks\":\n",
    "    os.chdir(\"..\")\n",
    "    cwd = os.getcwd().split(os.path.sep)\n",
    "print(f\">> current directory : {os.getcwd()}\")\n",
    "\n",
    "# add the root directory\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "# cache and data cache\n",
    "cache_path = path.join(os.getcwd() ,'.cache')\n",
    "dataset_path = path.join(cache_path, 'dataset')\n",
    "log_path = path.join(cache_path, 'logs')\n",
    "model_path = path.join(cache_path, 'models')\n",
    "print(f\">> cache path : {cache_path}\")\n",
    "print(f\">> model path : {model_path}\")\n",
    "print(f\">> dataset path : {dataset_path}\")\n",
    "print(f\">> logs path : {log_path}\")\n",
    "\n",
    "# import the different modules\n",
    "from src.data_module.hatexplain import CLSTokenHateXPlainDM\n",
    "from src.data_module.esnli import CLSTokenESNLIDM\n",
    "from src.data_module.yelp_hat import CLSTokenYelpHat50DM, CLSTokenYelpHatDM\n",
    "from pur_attention_key_reg import AttitModel\n",
    "from modules import metrics\n",
    "from notebooks.attention_based.utils.ckp_config import *\n",
    "\n",
    "# external librairies\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from modules.metrics.geometry import cosine_sim, effective_rank\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">> device : {DEVICE}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# HateXplain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "%%capture\n",
    "sim_k_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_v_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_emb_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "\n",
    "\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=999\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenHateXPlainDM(**dm_kwargs)\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "test_dataloader = dm.test_dataloader() # load the test dataset\n",
    "\n",
    "spec_ids = torch.tensor(dm.vocab([\"<cls>\", \"<pad>\", \"<unk>\"]), device=DEVICE)\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"hatexplain\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "cpt = torch.tensor([0, 0, 0, 0, 0], device=DEVICE)\n",
    "for l in range(5) :\n",
    "\n",
    "    # update the args for the model\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_hatexplain_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "    hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_hatexplain_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "    # the model\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "    model = model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.to(DEVICE)\n",
    "        pbar = tqdm(enumerate(test_dataloader), total = int(999/32))\n",
    "        for id_batch, batch in pbar:\n",
    "\n",
    "            pbar.set_description(\"proceed the similarity metric\")\n",
    "            ids = batch[\"token_ids\"].to(DEVICE)\n",
    "\n",
    "            # PADDING\n",
    "            padding_mask = batch[\"padding_mask\"].bool().to(DEVICE)\n",
    "            buff_mask = torch.isin(ids, spec_ids)\n",
    "            embedding_padding = padding_mask.clone()\n",
    "            embedding_padding[buff_mask] = 1.\n",
    "\n",
    "            # OUTPUTS\n",
    "            output = model(ids=ids, mask=padding_mask)\n",
    "            cl = output[\"logits\"].argmax(dim=-1)\n",
    "            cpt[l] += (cl == batch[\"y_true\"].to(DEVICE)).sum().item()\n",
    "            k, v, emb = output[\"key_embeddings\"], output[\"value_embeddings\"], output[\"hidden_states\"]\n",
    "\n",
    "            for i in range(l+1):\n",
    "                # calculus of the metrics\n",
    "                sim_k = cosine_sim(k[i], padding_mask, normalize=\"\")\n",
    "                sim_v = cosine_sim(v[i], padding_mask, normalize=\"\")\n",
    "                sim_e = cosine_sim(emb[i], embedding_padding, normalize=\"\")\n",
    "\n",
    "                # update dictionnaries\n",
    "                sim_k_dict[f\"n_layer={l+1}\"][i] += sim_k.sum().item()\n",
    "                sim_v_dict[f\"n_layer={l+1}\"][i] += sim_v.sum().item()\n",
    "                sim_emb_dict[f\"n_layer={l+1}\"][i] += sim_e.sum().item()\n",
    "\n",
    "    model = model.cpu()\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "for k in sim_k_dict:\n",
    "    sim_k_dict[k] = sim_k_dict[k] / 999\n",
    "    sim_v_dict[k] = sim_v_dict[k] / 999\n",
    "    sim_emb_dict[k] = sim_emb_dict[k] / 999\n",
    ";"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([62.4625, 62.4625, 63.6637, 63.9640, 62.7628])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpt / 999).cpu() * 100 # the accuracy (in %)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.71326747]),\n 'n_layer=2': array([0.69151901, 0.68288404]),\n 'n_layer=3': array([0.69846342, 0.68784525, 0.84177555]),\n 'n_layer=4': array([0.61357826, 0.61971813, 0.74860878, 0.83997919]),\n 'n_layer=5': array([0.62424775, 0.64732869, 0.77722902, 0.91285675, 0.97317868])}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_k_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.54221579]),\n 'n_layer=2': array([0.51039431, 0.7399584 ]),\n 'n_layer=3': array([0.60546832, 0.68796405, 0.88236577]),\n 'n_layer=4': array([0.59191521, 0.56141785, 0.78510146, 0.93110824]),\n 'n_layer=5': array([0.60675967, 0.67302059, 0.85818866, 0.95838471, 0.9922627 ])}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_v_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.30715777]),\n 'n_layer=2': array([0.30740158, 0.63975486]),\n 'n_layer=3': array([0.30707839, 0.65768343, 0.80064176]),\n 'n_layer=4': array([0.30735863, 0.54912228, 0.71639724, 0.8791464 ]),\n 'n_layer=5': array([0.30678413, 0.60209061, 0.7905752 , 0.9227977 , 0.98004375])}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_emb_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yelp Hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "%%capture\n",
    "sim_k_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_v_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_emb_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=999\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenYelpHatDM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "test_dataloader_yh = dm.test_dataloader()\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"yelphat\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "cpt = torch.tensor([0, 0, 0, 0, 0], device=DEVICE)\n",
    "\n",
    "for test_dataloader in test_dataloader_yh :\n",
    "\n",
    "    for l in range(5) :\n",
    "\n",
    "        # update the args for the model\n",
    "        model_args[\"num_layers\"] = l+1\n",
    "        ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_yelphat50_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "        hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_yelphat50_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "        # the model\n",
    "        model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "        model = model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model = model.to(DEVICE)\n",
    "            pbar = tqdm(enumerate(test_dataloader), total = int(999/32))\n",
    "            for id_batch, batch in pbar:\n",
    "\n",
    "                pbar.set_description(\"proceed the similarity metric\")\n",
    "                ids = batch[\"token_ids\"].to(DEVICE)\n",
    "\n",
    "                # PADDING\n",
    "                padding_mask = batch[\"padding_mask\"].bool().to(DEVICE)\n",
    "                buff_mask = torch.isin(ids, spec_ids)\n",
    "                embedding_padding = padding_mask.clone()\n",
    "                embedding_padding[buff_mask] = 1.\n",
    "\n",
    "                # OUTPUTS\n",
    "                output = model(ids=ids, mask=padding_mask)\n",
    "                cl = output[\"logits\"].argmax(dim=-1)\n",
    "                cpt[l] += (cl == batch[\"y_true\"].to(DEVICE)).sum().item()\n",
    "                k, v, emb = output[\"key_embeddings\"], output[\"value_embeddings\"], output[\"hidden_states\"]\n",
    "\n",
    "                assert len(v)+1 == len(emb), \"errors : (1)\"\n",
    "                assert len(k)+1 == len(emb), \"errors : (2)\"\n",
    "\n",
    "                for i in range(l+1):\n",
    "                    # calculus of the metrics\n",
    "                    sim_k = cosine_sim(k[i], padding_mask, normalize=\"\")\n",
    "                    sim_v = cosine_sim(v[i], padding_mask, normalize=\"\")\n",
    "                    sim_e = cosine_sim(emb[i], embedding_padding, normalize=\"\")\n",
    "\n",
    "                    # update dictionnaries\n",
    "                    sim_k_dict[f\"n_layer={l+1}\"][i] += sim_k.sum().item()\n",
    "                    sim_v_dict[f\"n_layer={l+1}\"][i] += sim_v.sum().item()\n",
    "                    sim_emb_dict[f\"n_layer={l+1}\"][i] += sim_e.sum().item()\n",
    "\n",
    "        model = model.cpu()\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "nb_samples = sum([len(test_dataloader_yh[i].dataset) for i in range(3)])\n",
    "\n",
    "for k in sim_k_dict:\n",
    "    sim_k_dict[k] = sim_k_dict[k] / nb_samples\n",
    "    sim_v_dict[k] = sim_v_dict[k] / nb_samples\n",
    "    sim_emb_dict[k] = sim_emb_dict[k] / nb_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.8702, 0.8638, 0.8676, 0.8560, 0.8817])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpt/nb_samples).cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.57841434]),\n 'n_layer=2': array([0.64860994, 0.55575706]),\n 'n_layer=3': array([0.59687076, 0.43072539, 0.5372692 ]),\n 'n_layer=4': array([0.71363631, 0.71653453, 0.70200274, 0.85986021]),\n 'n_layer=5': array([0.58451316, 0.54224598, 0.76112572, 0.81632189, 0.95989591])}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_k_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.3719648]),\n 'n_layer=2': array([0.40870349, 0.51055599]),\n 'n_layer=3': array([0.46146833, 0.37069772, 0.49411083]),\n 'n_layer=4': array([0.42850584, 0.61289558, 0.80302721, 0.90383451]),\n 'n_layer=5': array([0.41716203, 0.62437506, 0.77994665, 0.90231054, 0.97221654])}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_v_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.38078402]),\n 'n_layer=2': array([0.37996527, 0.50289467]),\n 'n_layer=3': array([0.38148685, 0.38971275, 0.44309147]),\n 'n_layer=4': array([0.3792807 , 0.5504015 , 0.74507838, 0.85944818]),\n 'n_layer=5': array([0.37956235, 0.54823069, 0.72569706, 0.86386779, 0.95190411])}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_emb_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# E-SNLI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=999\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenESNLIDM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "test_dataloader = dm.test_dataloader()\n",
    "\n",
    "spec_ids = torch.tensor(dm.vocab([\"<cls>\", \"<pad>\", \"<unk>\"]), device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "%%capture\n",
    "sim_k_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_v_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "sim_emb_dict = {\n",
    "    f\"n_layer={i+1}\" : np.zeros((i+1,)) for i in range(5)\n",
    "}\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"esnli\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "cpt = torch.tensor([0, 0, 0, 0, 0], device=DEVICE)\n",
    "for l in range(2) :\n",
    "\n",
    "    # update the args for the model\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_esnli_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "    hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_esnli_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "    # the model\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "    model = model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.to(DEVICE)\n",
    "        pbar = tqdm(enumerate(test_dataloader), total = int(999/32))\n",
    "        for id_batch, batch in pbar:\n",
    "\n",
    "            pbar.set_description(\"proceed the similarity metric\")\n",
    "            ids = batch[\"token_ids\"].to(DEVICE)\n",
    "\n",
    "            # padding\n",
    "            padding_mask = batch[\"padding_mask\"].bool().to(DEVICE)\n",
    "            buff_mask = torch.isin(ids, spec_ids)\n",
    "            embedding_padding = padding_mask.clone()\n",
    "            embedding_padding[buff_mask] = 1.\n",
    "\n",
    "            output = model(ids=ids, mask=padding_mask)\n",
    "\n",
    "            # check accuracy\n",
    "            cl = output[\"logits\"].argmax(dim=-1)\n",
    "            cpt[l] += (cl == batch[\"y_true\"].to(DEVICE)).sum().item()\n",
    "\n",
    "            # get the embeddings\n",
    "            k, v, emb = output[\"key_embeddings\"], output[\"value_embeddings\"], output[\"hidden_states\"]\n",
    "\n",
    "            for i in range(l+1):\n",
    "                # calculus of the metrics\n",
    "                sim_k = cosine_sim(k[i], padding_mask, normalize=\"\")\n",
    "                sim_v = cosine_sim(v[i], padding_mask, normalize=\"\")\n",
    "                sim_e = cosine_sim(emb[i], embedding_padding, normalize=\"\")\n",
    "\n",
    "                sim_k_dict[f\"n_layer={l+1}\"][i] += sim_k.sum().item()\n",
    "                sim_v_dict[f\"n_layer={l+1}\"][i] += sim_v.sum().item()\n",
    "                sim_emb_dict[f\"n_layer={l+1}\"][i] += sim_e.sum().item()\n",
    "\n",
    "    model = model.cpu()\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "nb_samples = len(test_dataloader.dataset)\n",
    "\n",
    "for k in sim_k_dict:\n",
    "    sim_k_dict[k] = sim_k_dict[k] / nb_samples\n",
    "    sim_v_dict[k] = sim_v_dict[k] / nb_samples\n",
    "    sim_emb_dict[k] = sim_emb_dict[k] / nb_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.6276, 0.7297, 0.0000, 0.0000, 0.0000])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cpt.cpu() / 999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.65682015]),\n 'n_layer=2': array([0.71875791, 0.48821352]),\n 'n_layer=3': array([0., 0., 0.]),\n 'n_layer=4': array([0., 0., 0., 0.]),\n 'n_layer=5': array([0., 0., 0., 0., 0.])}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_k_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.52405099]),\n 'n_layer=2': array([0.18200549, 0.74587911]),\n 'n_layer=3': array([0., 0., 0.]),\n 'n_layer=4': array([0., 0., 0., 0.]),\n 'n_layer=5': array([0., 0., 0., 0., 0.])}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_v_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_layer=1': array([0.35232755]),\n 'n_layer=2': array([0.34540131, 0.59773792]),\n 'n_layer=3': array([0., 0., 0.]),\n 'n_layer=4': array([0., 0., 0., 0.]),\n 'n_layer=5': array([0., 0., 0., 0., 0.])}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_emb_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}