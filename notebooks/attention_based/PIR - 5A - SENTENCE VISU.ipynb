{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualisation des cartes d'entropie"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons ici proposer des méthodes de visualisation des cartes d'attention sur les différentes phrases.\n",
    "Attention : la pluspart des outils qui seront utiles pour la visualisation ici seront présents dans le fichier `utils`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions for the visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      ">> current directory : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\n",
      ">> cache path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\n",
      ">> model path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\models\n",
      ">> dataset path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\dataset\n",
      ">> logs path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\logs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import torch\n",
    "cwd = os.getcwd().split(os.path.sep)\n",
    "\n",
    "# point to the git repository\n",
    "while cwd[-1] != \"ExplanationPairSentencesTasks\":\n",
    "    os.chdir(\"..\")\n",
    "    cwd = os.getcwd().split(os.path.sep)\n",
    "print(f\">> current directory : {os.getcwd()}\")\n",
    "\n",
    "# add the root directory\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "# cache and data cache\n",
    "cache_path = path.join(os.getcwd() ,'.cache')\n",
    "dataset_path = path.join(cache_path, 'dataset')\n",
    "log_path = path.join(cache_path, 'logs')\n",
    "model_path = path.join(cache_path, 'models')\n",
    "print(f\">> cache path : {cache_path}\")\n",
    "print(f\">> model path : {model_path}\")\n",
    "print(f\">> dataset path : {dataset_path}\")\n",
    "print(f\">> logs path : {log_path}\")\n",
    "\n",
    "from src.data_module.hatexplain import HateXPlainDM\n",
    "from pur_attention import AttitModel\n",
    "from modules import metrics\n",
    "from notebooks.attention_based.utils.ckp_config import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def html_render(model_outputs):\n",
    "    html = ''\n",
    "    table_len = len(model_outputs['GROUNDTRUTH']['Entropy'])\n",
    "    for i in range(table_len):\n",
    "        html += '<table>'\n",
    "        html += '<tr><th></th>' # One xtra head for model's name\n",
    "        for column_name in model_outputs['GROUNDTRUTH'].keys():\n",
    "            html+= '<th>'+ column_name +'</th>'\n",
    "        html += ' </tr>'\n",
    "        for name, model_content in model_outputs.items():\n",
    "            html += '<tr>'\n",
    "            html += '<td><b>' + name + '</b></td>'\n",
    "\n",
    "            for k, output in model_content.items():\n",
    "                displ = output[i] if output is not None else 'N/A'\n",
    "                if isinstance(displ, float):\n",
    "                    displ = str(round(displ, 3))\n",
    "                html += '<td>' + displ + '</td>'\n",
    "\n",
    "            html += '</tr>'\n",
    "\n",
    "        html += '</table>'\n",
    "    return html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def highlight_txt(tokens, attention, padding_filter=None):\n",
    "    \"\"\"\n",
    "    Build an HTML of text along its weights.\n",
    "    Args:\n",
    "        tokens: list of tokens\n",
    "        attention: list of attention weights\n",
    "        padding_filter: padding filter to be hidden from visual\n",
    "    \"\"\"\n",
    "    assert len(tokens) == len(attention), f'Length mismatch: f{len(tokens)} vs f{len(attention)}'\n",
    "\n",
    "    MAX_ALPHA = 0.8 # transparency\n",
    "\n",
    "    highlighted_text = ''\n",
    "    # just for the visualization we normalize\n",
    "    w_min, w_max = torch.min(attention), torch.max(attention)\n",
    "\n",
    "    # In case of uniform: highlight all text\n",
    "    if w_min == w_max:\n",
    "        w_min = 0.\n",
    "\n",
    "    w_norm = (attention - w_min)/(w_max - w_min)\n",
    "    w_norm = [w / MAX_ALPHA for w in w_norm]\n",
    "\n",
    "    if padding_filter is not None:\n",
    "        id_non_pad = [i for i, tk in enumerate(tokens) if tk != padding_filter]\n",
    "        w_norm = [w_norm[i] for i in id_non_pad]\n",
    "        tokens = [tokens[i] for i in id_non_pad]\n",
    "\n",
    "    highlighted_text = [f'<span style=\"background-color:rgba(135,206,250, {weight});\">{text}</span>' for weight, text in zip(w_norm, tokens)]\n",
    "\n",
    "    return ' '.join(highlighted_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One head models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HatexPlain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load the data\n",
    "# the hatexplain dataset\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=999,\n",
    "                 pur_attention=True)\n",
    "dm = HateXPlainDM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "\n",
    "test_dataloader = dm.test_dataloader() # load the test dataset\n",
    "# load the models\n",
    "hparams_path = path.join(log_path, \"PurAttention\", \"n_layer_1_htx_adadel\", 'hparams.yaml')\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entrop=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"hatexplain\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adadelta\"\n",
    "    )\n",
    "\n",
    "models_dict = {\n",
    "    f\"n_layer={i+1}\" : None for i in range(6)\n",
    "}\n",
    "\n",
    "for l in range(5) :\n",
    "    # for each iteration update the model args\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = gen_ckp(name=\"PurAttention\",num_layers=l+1, num_heads=1, log_path=log_path, dataset=\"hatexplain\")\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams_path, **model_args)\n",
    "    model = model.eval()\n",
    "    models_dict[f\"n_layer={l+1}\"] = model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E-SNLI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}