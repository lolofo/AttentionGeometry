{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> current directory : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\n",
      ">> cache path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\n",
      ">> model path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\models\n",
      ">> dataset path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\dataset\n",
      ">> logs path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\logs\n",
      ">> emb path : C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\n",
      ">> device : cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "cwd = os.getcwd().split(os.path.sep)\n",
    "\n",
    "# point to the git repository\n",
    "while cwd[-1] != \"ExplanationPairSentencesTasks\":\n",
    "    os.chdir(\"..\")\n",
    "    cwd = os.getcwd().split(os.path.sep)\n",
    "print(f\">> current directory : {os.getcwd()}\")\n",
    "\n",
    "# add the root directory\n",
    "sys.path.append(os.path.join(os.getcwd(), \"src\"))\n",
    "\n",
    "# cache and data cache\n",
    "cache_path = path.join(os.getcwd() ,'.cache')\n",
    "dataset_path = path.join(cache_path, 'dataset')\n",
    "log_path = path.join(cache_path, 'logs')\n",
    "model_path = path.join(cache_path, 'models')\n",
    "emb_path = path.join(cache_path, 'embeddings')\n",
    "print(f\">> cache path : {cache_path}\")\n",
    "print(f\">> model path : {model_path}\")\n",
    "print(f\">> dataset path : {dataset_path}\")\n",
    "print(f\">> logs path : {log_path}\")\n",
    "print(f\">> emb path : {emb_path}\")\n",
    "\n",
    "# import the different modules\n",
    "from src.data_module.hatexplain import CLSTokenHateXPlainDM\n",
    "from src.data_module.esnli import CLSTokenESNLIDM\n",
    "from src.data_module.yelp_hat import CLSTokenYelpHat50DM, CLSTokenYelpHatDM\n",
    "from pur_attention_key_reg import AttitModel\n",
    "\n",
    "from notebooks.attention_based.utils.attention_embeddings import *\n",
    "from notebooks.attention_based.utils.one_step_window import attention_metrics_res as one_step_window\n",
    "\n",
    "# external librairies\n",
    "import torch\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">> device : {DEVICE}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hatexplain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_hatexplain_1.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 61it [00:05, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([26785])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_hatexplain_2.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 61it [00:01, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([26785])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_hatexplain_3.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 61it [00:01, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([26785])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_hatexplain_4.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 61it [00:01, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([26785])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_hatexplain_5.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 61it [00:01, 37.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([26785])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_array = []\n",
    "res_rolling_array = []\n",
    "\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=-1\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenHateXPlainDM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"hatexplain\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "\n",
    "for l in range(5):\n",
    "\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_hatexplain_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "    hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_hatexplain_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "    # the model\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "    model = model.eval()\n",
    "\n",
    "    res = attention_metrics_res(model.to(DEVICE), dm, cache = os.path.join(emb_path, f\"matrix_e_hatexplain_{l+1}.pt\"), nb_data = 2000)\n",
    "    res_array.append(res)\n",
    "\n",
    "    \"\"\"res_windows = one_step_window(model.to(DEVICE), dm, nb_data = 900)\n",
    "    res_rolling_array.append(res_windows)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1 layer ---\n",
      "\n",
      "AUC - cos  :  0.6453655695112541\n",
      "AUC - attention  :  0.7085374490171078\n",
      "\n",
      "--- 2 layer ---\n",
      "\n",
      "AUC - cos  :  0.642540197764027\n",
      "AUC - attention  :  0.5190543639619913\n",
      "\n",
      "--- 3 layer ---\n",
      "\n",
      "AUC - cos  :  0.6440181538479587\n",
      "AUC - attention  :  0.5199078098001578\n",
      "\n",
      "--- 4 layer ---\n",
      "\n",
      "AUC - cos  :  0.6561134749328668\n",
      "AUC - attention  :  0.5146393865783421\n",
      "\n",
      "--- 5 layer ---\n",
      "\n",
      "AUC - cos  :  0.6570189931225057\n",
      "AUC - attention  :  0.5457106851987926\n"
     ]
    }
   ],
   "source": [
    "for i,res in enumerate(res_array):\n",
    "    print()\n",
    "    print(f\"--- {i+1} layer ---\")\n",
    "    print()\n",
    "    dict_print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Yelphat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_yelphat50_1.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 10it [00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([17402])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_yelphat50_2.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 10it [00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([17402])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_yelphat50_3.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 10it [00:00, 24.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([17402])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_yelphat50_4.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 10it [00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([17402])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_yelphat50_5.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 10it [00:00, 20.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed : torch.Size([17402])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_array = []\n",
    "res_rolling_array = []\n",
    "\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=-1\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenYelpHat50DM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"yelphat\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "\n",
    "for l in range(5):\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_yelphat50_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "    hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_yelphat50_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "    # the model\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "    model = model.eval()\n",
    "\n",
    "    res = attention_metrics_res(model.to(DEVICE), dm, cache = os.path.join(emb_path, f\"matrix_e_yelphat50_{l+1}.pt\"), nb_data = 2000)\n",
    "    res_array.append(res)\n",
    "\n",
    "    \"\"\"res_windows = one_step_window(model.to(DEVICE), dm, nb_data = 900)\n",
    "    res_rolling_array.append(res_windows)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1 layer ---\n",
      "\n",
      "AUC - cos  :  0.6099390794017335\n",
      "AUC - attention  :  0.7116495788771671\n",
      "\n",
      "--- 2 layer ---\n",
      "\n",
      "AUC - cos  :  0.593299380195236\n",
      "AUC - attention  :  0.600224247561349\n",
      "\n",
      "--- 3 layer ---\n",
      "\n",
      "AUC - cos  :  0.6157801018581223\n",
      "AUC - attention  :  0.6256304762209922\n",
      "\n",
      "--- 4 layer ---\n",
      "\n",
      "AUC - cos  :  0.6065181299778823\n",
      "AUC - attention  :  0.5497422215721981\n",
      "\n",
      "--- 5 layer ---\n",
      "\n",
      "AUC - cos  :  0.6049565216323993\n",
      "AUC - attention  :  0.5388016176212471\n"
     ]
    }
   ],
   "source": [
    "for i,res in enumerate(res_array):\n",
    "    print()\n",
    "    print(f\"--- {i+1} layer ---\")\n",
    "    print()\n",
    "    dict_print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# E-SNLI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_esnli_1.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 93it [00:02, 41.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done !\n",
      "test passed : torch.Size([47087])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\loicf\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "load the matrix at the location C:\\Users\\loicf\\Documents\\IRISA\\ExplanationPairSentencesTasks\\.cache\\embeddings\\matrix_e_esnli_2.pt ... loading done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "proceed the cosine map: : 93it [00:01, 48.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done !\n",
      "test passed : torch.Size([47087])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_array = []\n",
    "res_rolling_array = []\n",
    "\n",
    "dm_kwargs = dict(cache_path=dataset_path,\n",
    "                 batch_size=32,\n",
    "                 num_workers=0,\n",
    "                 n_data=-1\n",
    "                 )\n",
    "\n",
    "dm = CLSTokenESNLIDM(**dm_kwargs)\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"test\")\n",
    "\n",
    "model_args = dict(\n",
    "        cache_path=model_path,\n",
    "        mode=\"exp\",\n",
    "        vocab=dm.vocab,\n",
    "        lambda_entropy=0,\n",
    "        lambda_supervise=0,\n",
    "        lambda_lagrange=0,\n",
    "        pretrained_vectors=\"glove.840B.300d\",\n",
    "        num_layers=1,\n",
    "        num_heads=1,\n",
    "        d_embedding=300,\n",
    "        data=\"esnli\",\n",
    "        num_class=dm.num_class,\n",
    "        opt=\"adam\"\n",
    ")\n",
    "\n",
    "for l in range(2):\n",
    "    model_args[\"num_layers\"] = l+1\n",
    "    ckp = os.path.join(log_path, \"PurAttention\", f\"run=0_esnli_l=0{l+1}_h=1_adam\", \"checkpoints\", \"best.ckpt\")\n",
    "    hparams = os.path.join(log_path, \"PurAttention\", f\"run=0_esnli_l=0{l+1}_h=1_adam\", \"hparams.yaml\")\n",
    "\n",
    "    # the model\n",
    "    model = AttitModel.load_from_checkpoint(ckp, hparams_file=hparams, **model_args)\n",
    "    model = model.eval()\n",
    "\n",
    "    res = attention_metrics_res(model.to(DEVICE), dm, cache = os.path.join(emb_path, f\"matrix_e_esnli_{l+1}.pt\"), nb_data = 2000)\n",
    "    res_array.append(res)\n",
    "\n",
    "    \"\"\"res_windows = one_step_window(model.to(DEVICE), dm, nb_data = 900)\n",
    "    res_rolling_array.append(res_windows)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1 layer ---\n",
      "\n",
      "AUC - cos  :  0.5674373093624985\n",
      "AUC - attention  :  0.6013851855942991\n",
      "\n",
      "--- 2 layer ---\n",
      "\n",
      "AUC - cos  :  0.6887597757945834\n",
      "AUC - attention  :  0.5788340498030906\n"
     ]
    }
   ],
   "source": [
    "for i,res in enumerate(res_array):\n",
    "    print()\n",
    "    print(f\"--- {i+1} layer ---\")\n",
    "    print()\n",
    "    dict_print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}